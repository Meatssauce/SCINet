{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a StackedSCINet to forecast BTC/USD price time seires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'livelossplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MASONZ~1\\AppData\\Local\\Temp/ipykernel_18172/136209918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlotLossesKeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'livelossplot'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from ta.momentum import AwesomeOscillatorIndicator\n",
    "from ta.trend import ADXIndicator\n",
    "from ta.volatility import AverageTrueRange\n",
    "from ta.volume import AccDistIndexIndicator\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from SCINet import make_simple_scinet, make_simple_stacked_scinet, StackedSCINetLoss\n",
    "from gtda.time_series import SlidingWindow, Stationarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_length, horizon = 32, 2\n",
    "learning_rate = 5e-3\n",
    "h, kernel_size, L, K = 4, 5, 3, 3\n",
    "kernel_regularizer = tf.keras.regularizers.L1L2(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mason Z\\PycharmProjects\\SCINet\\venv\\lib\\site-packages\\ta\\trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "c:\\Users\\Mason Z\\PycharmProjects\\SCINet\\venv\\lib\\site-packages\\ta\\trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    }
   ],
   "source": [
    "# Load stocks data\n",
    "data = pd.read_csv(os.path.join('crypto_data', 'Bitstamp_BTCUSD_1h.csv')).set_index('date')\n",
    "data = data.drop(columns=['unix', 'symbol', 'Volume BTC'])\n",
    "prices_cols = data.columns\n",
    "\n",
    "# Clean NaN values\n",
    "data = dropna(data)\n",
    "\n",
    "# Add ta features filling NaN values\n",
    "data['ao'] = AwesomeOscillatorIndicator(high=data['high'], low=data['low'], fillna=True).awesome_oscillator()\n",
    "data['adi'] = AccDistIndexIndicator(high=data['high'], low=data['low'], close=data['close'], volume=data['Volume USD'],\n",
    "                                    fillna=True).acc_dist_index()\n",
    "data['atr'] = AverageTrueRange(high=data['high'], low=data['low'], close=data['close'],\n",
    "                               fillna=True).average_true_range()\n",
    "\n",
    "adx_indicator = ADXIndicator(high=data['high'], low=data['low'], close=data['close'], fillna=True)\n",
    "data['adx'] = adx_indicator.adx()\n",
    "data['adx_pos'] = adx_indicator.adx_pos()\n",
    "data['adx_neg'] = adx_indicator.adx_neg()\n",
    "\n",
    "data = data[27:]\n",
    "indicator_cols = data.columns[len(prices_cols):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting, preprocessing and target preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mason Z\\PycharmProjects\\SCINet\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "c:\\Users\\Mason Z\\PycharmProjects\\SCINet\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "c:\\Users\\Mason Z\\PycharmProjects\\SCINet\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "# Split data -- train:val:test == 6:2:2\n",
    "train_cutoff, val_cutoff = int(len(data) * 0.6), int(len(data) * 0.8)\n",
    "train_data, val_data, test_data = data[:train_cutoff], data[train_cutoff:val_cutoff], data[val_cutoff:]\n",
    "\n",
    "stationariser = Stationarizer()\n",
    "train_data[1:][prices_cols] = stationariser.fit_transform(train_data[prices_cols])\n",
    "val_data[1:][prices_cols] = stationariser.transform(val_data[prices_cols])\n",
    "test_data[1:][prices_cols] = stationariser.transform(test_data[prices_cols])\n",
    "\n",
    "train_data, val_data, test_data = train_data[1:], val_data[1:], test_data[1:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# Segment into train/val/test examples (may use stride < size for train_data only but may cause data leak)\n",
    "windows = SlidingWindow(size=lag_length + horizon, stride=2)\n",
    "train_data = windows.fit_transform(train_data)\n",
    "windows = SlidingWindow(size=lag_length + horizon, stride=lag_length + horizon)\n",
    "val_data = windows.fit_transform(val_data)\n",
    "test_data = windows.transform(test_data)\n",
    "\n",
    "# Split all time series segments into x and y\n",
    "X_train, y_train = train_data[:, :-horizon, :], train_data[:, -horizon:, :]\n",
    "X_val, y_val = val_data[:, :-horizon, :], val_data[:, -horizon:, :]\n",
    "X_test, y_test = test_data[:, :-horizon, :], test_data[:, -horizon:, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = os.path.join('saved_models_with_logs', 'BTC-USD', datetime.now().strftime('%HH%MM %d-%b-%Y'))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "log_dir = os.path.join(output_dir, 'logs')\n",
    "diagram_path = os.path.join(output_dir, 'model_diagram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lookback_window (InputLayer)    [(None, 32, 11)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stacked_scinet (StackedSCINet)  (3, None, 2, 11)     434478      lookback_window[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 2, 11)        0           stacked_scinet[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Identity)              (None, 2, 11)        0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "intermediates (Identity)        (3, None, 2, 11)     0           stacked_scinet[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 434,478\n",
      "Trainable params: 434,478\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "299/299 [==============================] - 46s 110ms/step - loss: 281.5156 - intermediates_loss: 211.2412 - outputs_mse: 1.7933 - outputs_mae: 0.4507 - val_loss: 154.4349 - val_intermediates_loss: 127.2100 - val_outputs_mse: 0.3232 - val_outputs_mae: 0.2682tes_loss: 211.3406 - outputs_mse: 1.7941 - outputs_mae: 0.\n",
      "Epoch 2/500\n",
      "299/299 [==============================] - 29s 96ms/step - loss: 160.4416 - intermediates_loss: 140.2340 - outputs_mse: 0.4386 - outputs_mae: 0.2960 - val_loss: 140.2590 - val_intermediates_loss: 123.9059 - val_outputs_mse: 0.3223 - val_outputs_mae: 0.2590terme\n",
      "Epoch 3/500\n",
      "299/299 [==============================] - 31s 105ms/step - loss: 154.7064 - intermediates_loss: 138.3106 - outputs_mse: 0.4408 - outputs_mae: 0.2926 - val_loss: 141.8241 - val_intermediates_loss: 125.0033 - val_outputs_mse: 0.3217 - val_outputs_mae: 0.2641\n",
      "Epoch 4/500\n",
      "299/299 [==============================] - 29s 98ms/step - loss: 153.0007 - intermediates_loss: 137.0425 - outputs_mse: 0.4345 - outputs_mae: 0.2896 - val_loss: 140.6003 - val_intermediates_loss: 123.8813 - val_outputs_mse: 0.3201 - val_outputs_mae: 0.2618ediates_loss: 137.9375 - outputs_mse: 0.4008  - ETA - ETA: 4s - loss: 153.6254 - intermediates_loss: 137.6352 - outputs_mse: 0.4523 - outputs_mae: 0.29 - ETA: 4s - loss: 153.5957 - intermediates_loss: 137.6084 - ETA: 2s - loss: 153.3550 - intermediates_loss\n",
      "Epoch 5/500\n",
      "299/299 [==============================] - 32s 107ms/step - loss: 153.1326 - intermediates_loss: 137.0651 - outputs_mse: 0.4334 - outputs_mae: 0.2878 - val_loss: 138.7206 - val_intermediates_loss: 122.6607 - val_outputs_mse: 0.3195 - val_outputs_mae: 0.2573\n",
      "Epoch 6/500\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 153.3286 - intermediates_loss: 136.9387 - outputs_mse: 0.4332 - outputs_mae: 0.2921 - val_loss: 140.4097 - val_intermediates_loss: 123.4858 - val_outputs_mse: 0.3174 - val_outputs_mae: 0.2614\n",
      "Epoch 7/500\n",
      "299/299 [==============================] - 30s 101ms/step - loss: 152.9058 - intermediates_loss: 136.4056 - outputs_mse: 0.4314 - outputs_mae: 0.2868 - val_loss: 138.5738 - val_intermediates_loss: 122.3898 - val_outputs_mse: 0.3197 - val_outputs_mae: 0.2582156.2335 - intermediates_loss: 139.8768 - outputs_mse: 0.7080 - outpu - ETA: 22s - loss: 154.8434 - intermediates_loss: 138.4693 - outputs_mse: 0.6385 - outputs_mae: 0.29 - ETA: 22s - loss: 155.2607 - intermediates_loss: 138.8793 - outputs_mse: 0.6332 - out - ETA: 20s - loss: 155.0663 - intermediates_loss: 138.6376 - outputs_mse: 0.5929 - outputs_m - ETA: 19s - loss:  - ETA: 10s - loss: 152.5046 - intermediates_loss: 136.0499 - outputs_mse: 0.4693 - o - ETA: 9s - loss: 152.2990 - intermediates_loss: 135.8605 - outputs_mse: 0.46 - ETA: 8s - loss: 152.6255 - intermediates_loss: 136.2121 - outputs_mse: 0. - ETA: 6s - loss: 152.4510 - intermediates_loss: 136.0349 - - ETA: 4s - loss: 152.7881 - intermediates_loss: 136.3394 - outputs_mse: 0.4493 - outputs - ETA: 4s - loss: 153.1868 - intermediates_loss: 136.7191 - outputs_mse: 0.4495 - outputs_mae: 0.28 - ETA: 3s - loss: 153.1296 - intermediates_loss: 136.6585 - outputs - ETA: 2s - loss: 153.2534 - intermediates_loss: 136.7467 - outputs_mse: 0.4420 - outputs_mae: 0.28 - ETA: 2s - loss: 153.2522 - intermediates_loss: 136.7449 - outputs_mse: 0.4414 - - ETA: 1s - loss: 152.9669 - intermediates_loss: 136.4573 - outputs_mse: 0.43\n",
      "Epoch 8/500\n",
      "299/299 [==============================] - 31s 102ms/step - loss: 152.6537 - intermediates_loss: 136.0550 - outputs_mse: 0.4318 - outputs_mae: 0.2885 - val_loss: 140.3458 - val_intermediates_loss: 122.3241 - val_outputs_mse: 0.3221 - val_outputs_mae: 0.26515121 - intermediates_loss: 134.6273 - outputs_ms - ETA: 24s - loss: 152.2805 - intermediates_loss: 136.4799 - outputs_mse: - ETA: 21s - loss: 151.9926 - intermediates_loss: 136.0688 - outputs_mse: 0.3264 - outputs_mae: 0.28 - ETA: 21s - l - ETA: 12s - loss: 153.7998 - intermedia - ETA: 8s - loss: 154.1570 -  - ETA: \n",
      "Epoch 9/500\n",
      "299/299 [==============================] - 31s 102ms/step - loss: 153.3479 - intermediates_loss: 136.3477 - outputs_mse: 0.4361 - outputs_mae: 0.2893 - val_loss: 138.0421 - val_intermediates_loss: 120.4586 - val_outputs_mse: 0.3132 - val_outputs_mae: 0.2565ss: 135.6936 - outputs_mse: 0.4678 - outputs - ETA: 9s - loss: 152.8094 - intermediates_loss: 135.9267 - outputs_m - ETA: 8s - ETA: 3s - loss: 153.8292 - intermediates_loss: 136.9053 - outputs_mse: 0.4516 - outputs_mae - ETA: 3s - loss: 153.8925 - interm\n",
      "Epoch 10/500\n",
      "299/299 [==============================] - 30s 101ms/step - loss: 153.6294 - intermediates_loss: 136.2474 - outputs_mse: 0.4337 - outputs_mae: 0.2900 - val_loss: 139.2704 - val_intermediates_loss: 121.8597 - val_outputs_mse: 0.3177 - val_outputs_mae: 0.25628308 - intermediates_loss: 136.4541 - outputs_mse: 0.4168 - outputs - ETA: 0s - loss: 153.9782 - intermediates_loss: 136.5952 - outputs_mse: 0.4371 - outputs\n",
      "Epoch 11/500\n",
      "299/299 [==============================] - 32s 107ms/step - loss: 152.9647 - intermediates_loss: 135.6881 - outputs_mse: 0.4327 - outputs_mae: 0.2879 - val_loss: 138.2519 - val_intermediates_loss: 120.4968 - val_outputs_mse: 0.3108 - val_outputs_mae: 0.2587loss: 151.4460 - intermediates_loss: 134.2213 - outputs_mse: 0.3 - ETA: 24s - loss: 150.3097 - intermediates_loss: 133.2402 - - ETA: 19s - loss: 151.7975 - intermediates_loss: 135.0842 - outputs_mse: 0.3401 - ou - ETA: 17s - - ETA: 4s - loss: 152.9614 - intermediates_loss: 135.8040 - outputs_mse: 0.4403 - outputs_m - ETA: 4s - loss: 1\n",
      "Epoch 12/500\n",
      "299/299 [==============================] - 32s 107ms/step - loss: 153.7559 - intermediates_loss: 136.2567 - outputs_mse: 0.4321 - outputs_mae: 0.2902 - val_loss: 138.1110 - val_intermediates_loss: 119.7416 - val_outputs_mse: 0.3092 - val_outputs_mae: 0.2505loss: 153.8261 - intermediates_loss: 136.766 - ETA: 17s - loss: 154.4834 - intermediates_loss: 137.3170  - ETA: 12s - loss: 154.0695 - intermediates_loss: 136.8227 - outputs_mse: 0.4808 - outpu - ETA: 10s - loss: 153.4055 - - ETA: 6s - loss: 153.9843 - intermediates_loss: 136.6635 - outputs_mse: 0.4580 - out\n",
      "Epoch 13/500\n",
      "299/299 [==============================] - 31s 102ms/step - loss: 153.7596 - intermediates_loss: 135.9518 - outputs_mse: 0.4340 - outputs_mae: 0.2892 - val_loss: 141.0012 - val_intermediates_loss: 122.5079 - val_outputs_mse: 0.3167 - val_outputs_mae: 0.2606ntermediates_loss: 136.7237 - outputs_mse: 0.5250 - outputs_mae: 0.290 - ETA: 18s - loss: 154.1413 - intermediates_loss: 136.7057 - outputs_mse: 0.5230 - outputs - ETA: 16s - loss: 153.3285 - intermediates_loss: 135.8273 - outputs_mse: 0.5006 - outputs_mae: 0. - ETA: 16s - loss - ETA: 3s - loss: 153.9626 - interm\n",
      "Epoch 14/500\n",
      "299/299 [==============================] - 30s 99ms/step - loss: 154.2593 - intermediates_loss: 136.3927 - outputs_mse: 0.4410 - outputs_mae: 0.2906 - val_loss: 140.6061 - val_intermediates_loss: 122.5211 - val_outputs_mse: 0.3165 - val_outputs_mae: 0.2636intermediates_loss: 133.3094 - out - ETA: 23s - loss: 154.3766 - intermediates_loss: 136.4704  - ETA: 19s - loss: 155.075 - ETA: 11s - loss: 153.6648 - intermediates_loss: 135.9497 - outputs_mse: 0.4508 - - ETA: 9s - loss: 153.2520 - intermediates_loss: 135.4868 - outputs_mse: 0. - ETA: 8s - loss: 153.3923 - intermediates_loss: 135.5997 - outputs_mse: 0.4351 - outputs_mae: 0. - ETA: 8s - loss: 153.6809 - intermediates_loss: 135.8821 - out - ETA: 6s - loss: 153.7272 - intermediates_loss: 135.8681 - outputs_mse: \n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as scinet_layer_call_and_return_conditional_losses, scinet_layer_call_fn, scinet_layer_call_and_return_conditional_losses, scinet_layer_call_fn, scinet_layer_call_and_return_conditional_losses while saving (showing 5 of 2265). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_with_logs\\BTC-USD\\21H17M 04-Jan-2022\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models_with_logs\\BTC-USD\\21H17M 04-Jan-2022\\assets\n"
     ]
    }
   ],
   "source": [
    "# Proceed with SCINet\n",
    "model = make_simple_stacked_scinet(X_train.shape, horizon=horizon, K=K, L=L, h=h, kernel_size=kernel_size,\n",
    "                                   learning_rate=learning_rate, kernel_regularizer=kernel_regularizer,\n",
    "                                   diagram_path=diagram_path)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0, verbose=1, restore_best_weights=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=500,\n",
    "                    callbacks=[early_stopping, tensorboard_callback])\n",
    "\n",
    "# Save model and training history\n",
    "model.save(output_dir)\n",
    "pd.DataFrame(history.history).to_csv(os.path.join(output_dir, 'train_history.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot errors and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some metrics\n",
    "plt.plot(history.history['outputs_mae'])\n",
    "plt.plot(history.history['val_outputs_mae'])\n",
    "plt.title('model error')\n",
    "plt.ylabel('mean absolute error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.savefig(os.path.join(output_dir, 'outputs_mae.png'))\n",
    "plt.clf()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.savefig(os.path.join(output_dir, 'loss.png'))\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 45ms/step - loss: 140.7272 - intermediates_loss: 123.1438 - outputs_mse: 0.3363 - outputs_mae: 0.2626\n",
      "scores: [140.72720336914062, 123.14376068115234, 0.3363029956817627, 0.2625609338283539]\n",
      "0.2625609452025969\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct/load model\n",
    "# output_dir = 'saved_models_with_logs/BTC-USD/18H11M 04-Jan-2022'\n",
    "model = tf.keras.models.load_model(output_dir, custom_objects={'StackedSCINetLoss': StackedSCINetLoss()})\n",
    "\n",
    "# Evaluate\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'scores: {scores}')\n",
    "\n",
    "# Predict\n",
    "y_pred, _ = model.predict(X_test, batch_size=1)\n",
    "print(np.mean(np.abs((y_pred - y_test))))  # manual mae for sanity check\n",
    "\n",
    "y_pred = scaler.inverse_transform(y_pred.reshape(-1, 11))\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 11))\n",
    "columns = pd.MultiIndex.from_product([['test', 'pred'], data.columns])\n",
    "df = pd.DataFrame(np.concatenate((y_test, y_pred), axis=1), columns=columns)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c77edf5299af0ea0bcad90dcaba2a556fa6f4780548d9d9c93ad38a630e318cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
